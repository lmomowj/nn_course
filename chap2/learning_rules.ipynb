{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b88022",
   "metadata": {},
   "source": [
    "# 神经网络学习规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45c94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "from nn_tool.activation import *\n",
    "from nn_tool import activation as ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383faeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear 函数\n",
    "def linear(x,w):\n",
    "    # x,w 行向量\n",
    "    return np.dot(w,x.T)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b99a5f",
   "metadata": {},
   "source": [
    "##  Hebb 学习规则"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe54c90",
   "metadata": {},
   "source": [
    "&nbsp;学习信号: &nbsp; $r = f(net) = f(W X^T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af968d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebb学习规则\n",
    "def hebb(x,w,act='sgn'):\n",
    "    # x,w 行向量\n",
    "    # hebb规则：r(x)    \n",
    "    net = linear(x,w)\n",
    "    print('净输入: net = w * x.T = %.3f'%net)    \n",
    "    if act == 'sgn':\n",
    "        out = np.sign(net)\n",
    "    elif act == 'sigmoid_d':\n",
    "        out = Sigmoid_d().value(net)\n",
    "    elif act == 'tanh':\n",
    "        out = np.tanh(net)\n",
    "    print('实际输出: o = f(net) = %.3f'% out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3163ff25",
   "metadata": {},
   "source": [
    "##  Perceptron (感知器) 学习规则"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f79e2",
   "metadata": {},
   "source": [
    "&nbsp;学习信号: &nbsp; $r = d - o = d - f(net) = d - \\mathrm{sgn}(W X^T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92a41f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron 学习规则\n",
    "def perceptron(x,y,w):\n",
    "    # x,w 行向量\n",
    "    # perceptron 学习规则：r(x)\n",
    "    net = linear(x,w)\n",
    "    print('净输入: net = w * x.T =%.3f'% net)\n",
    "    out = np.sign(net)\n",
    "    print('实际输出: o = f(net) = %.3f'% out)\n",
    "    return y -out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99269b0",
   "metadata": {},
   "source": [
    "##  $\\delta$ 学习规则"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e21d3b",
   "metadata": {},
   "source": [
    "&nbsp;学习信号: &nbsp; $r = [d - f(net)]f'(net) = [d - f(W X^T)]f'(W X^T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a97400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta学习规则\n",
    "def delta(x,y,w,act='logistic'):\n",
    "    # x,w 行向量\n",
    "    # Delta学习规则：r(x)    \n",
    "    net = linear(x,w)\n",
    "    print('净输入: net = w * x.T = %.3f'%net)  \n",
    "    # 激活函数\n",
    "    func = eval(f'{ac.func_name[act]}()')\n",
    "    out = func.value(net)\n",
    "    df = func.gradient_value(net)\n",
    "    print('实际输出: o = f(net) = %.3f'% out)\n",
    "    print(\"导数：f'(net) = %.3f\"% df)\n",
    "    return (y-out)*df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e61d01",
   "metadata": {},
   "source": [
    "##  Widrow-Hoff (最小均方)学习规则"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0ee0c",
   "metadata": {},
   "source": [
    "&nbsp;学习信号: &nbsp; $r = d - net = d - W X^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6270f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widrow-hoff (LMS)学习规则\n",
    "def LMS(x,y,w):\n",
    "    # x,w 行向量\n",
    "    # Widrow-hoff (LMS)学习规则：r(x)    \n",
    "    out = linear(x,w)\n",
    "    print('净输入: net = w * x.T = %.3f'%out)\n",
    "    print('实际输出: o = net = %.3f'% out)\n",
    "    return y-out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395dfbfc",
   "metadata": {},
   "source": [
    "##  Correlation (相关)学习规则"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b33950",
   "metadata": {},
   "source": [
    "&nbsp;学习信号: &nbsp; $r = d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b685a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation学习规则\n",
    "def corre(x,y,w):\n",
    "    # x,w 行向量\n",
    "    # Correlation学习规则：r = y \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26c3ec",
   "metadata": {},
   "source": [
    "##  Winner-Take-All (胜者为王)学习规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6693c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37589b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9192f234",
   "metadata": {},
   "source": [
    "&nbsp; &nbsp; 权值更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac1e8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 权值更新\n",
    "def update(epoch,X,y,w,rule,act,lr): \n",
    "    i = epoch % X.shape[0]\n",
    "    print(\"\\nEpoch: %d\"% epoch)\n",
    "    print('当前输入的训练数据: ',X[i],y[i])\n",
    "    # print('Current input training data: ',X[i])\n",
    "    \n",
    "    #func = eval(f'{rule}') # 学习规则\n",
    "    #rs = func(X[i],y[i],w,act)   # 学习信号(实际输出)    \n",
    "    if rule == 'hebb':  \n",
    "        rs = hebb(X[i],w,act)    # 学习信号\n",
    "    elif rule == 'perceptron':\n",
    "        rs = perceptron(X[i],y[i],w)    # 学习信号\n",
    "    elif rule == 'delta':\n",
    "        rs = delta(X[i],y[i],w,act)\n",
    "    elif rule == 'LMS':\n",
    "        rs = LMS(X[i],y[i],w)\n",
    "    print('学习信号：r(w,x,d) = %.3f'% rs)\n",
    "    dw = lr * rs * X[i]   # 权值调整量\n",
    "    w = w+dw  \n",
    "    print('更新的权值向量: ',w)\n",
    "    #print('Updated weight vector: ',w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1acbc",
   "metadata": {},
   "source": [
    "&nbsp; &nbsp; 运行权值学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b05f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行 权值学习\n",
    "def runner(X,y=None,rule='hebb',act='sgn',lr=0.1,epochs=10,init_w=None,init_T=None):\n",
    "    # 样本\n",
    "    if y is None:\n",
    "        y = X.shape[0]*[None]\n",
    "    # 初始化权向量\n",
    "    if init_w is None:\n",
    "        w_ = np.zeros(X_.shape[1])  \n",
    "    else:   \n",
    "        w_ = np.array(init_w)        \n",
    "    print('初始权值向量: ',w_)\n",
    "    #print('Initial weight vector: ',w_)\n",
    "    \n",
    "    # 更新权值向量 （训练）\n",
    "    for epoch in range(epochs):   \n",
    "        w = update(epoch,X,y,w_,rule,act,lr)        \n",
    "        if (w == w_).all():\n",
    "            print('\\n学习结束')\n",
    "            print(f'算法迭代次数: {epoch}')\n",
    "            break\n",
    "        else:\n",
    "            w_ = w        \n",
    "    return w_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e87852b",
   "metadata": {},
   "source": [
    "&nbsp; $\\cdot $ &nbsp; Hebbian学习规则的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b69bac71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可选择的激活函数： ['unit', 'sgn', 'logistic', 'tanh', 'sigmoid_d', 'piecewise_s', 'piecewise_d', 'hard_logistic', 'hard_tanh', 'relu', 'leakyRelu', 'elu', 'softplus', 'swish', 'gelu', 'softmax']\n",
      "\n",
      "学习规则：hebb\n",
      "激活函数：SGN\n",
      "学习率：1\n",
      "初始权值向量:  [ 1.  -1.   0.   0.5]\n",
      "\n",
      "Epoch: 0\n",
      "当前输入的训练数据:  [ 1.  -2.   1.5  0. ] None\n",
      "净输入: net = w * x.T = 3.000\n",
      "实际输出: o = f(net) = 1.000\n",
      "学习信号：r(w,x,d) = 1.000\n",
      "更新的权值向量:  [ 2.  -3.   1.5  0.5]\n",
      "\n",
      "Epoch: 1\n",
      "当前输入的训练数据:  [ 1.  -0.5 -2.  -1.5] None\n",
      "净输入: net = w * x.T = -0.250\n",
      "实际输出: o = f(net) = -1.000\n",
      "学习信号：r(w,x,d) = -1.000\n",
      "更新的权值向量:  [ 1.  -2.5  3.5  2. ]\n",
      "\n",
      "Epoch: 2\n",
      "当前输入的训练数据:  [ 0.   1.  -1.   1.5] None\n",
      "净输入: net = w * x.T = -3.000\n",
      "实际输出: o = f(net) = -1.000\n",
      "学习信号：r(w,x,d) = -1.000\n",
      "更新的权值向量:  [ 1.  -3.5  4.5  0.5]\n"
     ]
    }
   ],
   "source": [
    "print('可选择的激活函数：',list(ac.func_name.keys()))\n",
    "# Hebbian学习规则\n",
    "\n",
    "# P33 例2.1 样本\n",
    "X = np.array([[1,-2,1.5,0],[1,-0.5,-2,-1.5],[0,1,-1,1.5]])\n",
    "lr = 1    # 学习率\n",
    "rule =  'hebb' # 学习规则\n",
    "act =  'sgn' # 'sigmoid_d' #   # 激活函数\n",
    "epochs = 3    # 训练次数\n",
    "init_w = np.array([1,-1,0,0.5])  # 初始化权向量  \n",
    "\n",
    "print(f'\\n学习规则：{rule}')\n",
    "print('激活函数：{}'.format(ac.func_name[act]))\n",
    "print(f'学习率：{lr}')\n",
    "\n",
    "final_w = runner(X,y=None,rule=rule,act=act,lr=lr,epochs=epochs,init_w=init_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc0c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "学习规则：hebb\n",
      "激活函数：Sigmoid_d\n",
      "学习率：1\n",
      "初始权值向量:  [ 1 -1]\n",
      "\n",
      "Epoch: 0\n",
      "当前输入的训练数据:  [ 1 -2] None\n",
      "净输入: net = w * x.T = 3.000\n",
      "实际输出: o = f(net) = 0.905\n",
      "学习信号：r(w,x,d) = 0.905\n",
      "更新的权值向量:  [ 1.905 -2.81 ]\n",
      "\n",
      "Epoch: 1\n",
      "当前输入的训练数据:  [0 1] None\n",
      "净输入: net = w * x.T = -2.810\n",
      "实际输出: o = f(net) = -0.886\n",
      "学习信号：r(w,x,d) = -0.886\n",
      "更新的权值向量:  [ 1.905 -3.697]\n",
      "\n",
      "Epoch: 2\n",
      "当前输入的训练数据:  [2 3] None\n",
      "净输入: net = w * x.T = -7.280\n",
      "实际输出: o = f(net) = -0.999\n",
      "学习信号：r(w,x,d) = -0.999\n",
      "更新的权值向量:  [-0.092 -6.693]\n",
      "\n",
      "Epoch: 3\n",
      "当前输入的训练数据:  [1 1] None\n",
      "净输入: net = w * x.T = -6.785\n",
      "实际输出: o = f(net) = -0.998\n",
      "学习信号：r(w,x,d) = -0.998\n",
      "更新的权值向量:  [-1.09 -7.69]\n"
     ]
    }
   ],
   "source": [
    "# Hebbian学习规则\n",
    "# 作业： P40 习题2.4\n",
    "# (1) act = 'sgn'; (2) act = 'sigmoid_d'\n",
    "X = np.array([[1,-2],[0,1],[2,3],[1,1]])\n",
    "print(X.shape)\n",
    "lr = 1    # 学习率\n",
    "rule =  'hebb' # 学习规则\n",
    "act = 'sigmoid_d' #   'sgn' #  # 激活函数\n",
    "epochs = 4    # 训练次数\n",
    "init_w = np.array([1,-1])  # 初始化权向量  \n",
    "\n",
    "print(f'学习规则：{rule}')\n",
    "print('激活函数：{}'.format(ac.func_name[act]))\n",
    "print(f'学习率：{lr}')\n",
    "\n",
    "final_w = runner(X,y=None,rule=rule,act=act,lr=lr,epochs=epochs,init_w=init_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a22ee5",
   "metadata": {},
   "source": [
    "&nbsp; $\\cdot $ &nbsp; 感知器学习规则的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f03363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学习规则：perceptron\n",
      "激活函数：SGN\n",
      "学习率：1\n",
      "初始权值向量:  [0 1 0]\n",
      "\n",
      "Epoch: 0\n",
      "当前输入的训练数据:  [ 2  1 -1] -1\n",
      "净输入: net = w * x.T =1.000\n",
      "实际输出: o = f(net) = 1.000\n",
      "学习信号：r(w,x,d) = -2.000\n",
      "更新的权值向量:  [-4 -1  2]\n",
      "\n",
      "Epoch: 1\n",
      "当前输入的训练数据:  [ 0 -1 -1] 1\n",
      "净输入: net = w * x.T =-1.000\n",
      "实际输出: o = f(net) = -1.000\n",
      "学习信号：r(w,x,d) = 2.000\n",
      "更新的权值向量:  [-4 -3  0]\n",
      "\n",
      "Epoch: 2\n",
      "当前输入的训练数据:  [ 2  1 -1] -1\n",
      "净输入: net = w * x.T =-11.000\n",
      "实际输出: o = f(net) = -1.000\n",
      "学习信号：r(w,x,d) = 0.000\n",
      "更新的权值向量:  [-4 -3  0]\n",
      "\n",
      "学习结束\n",
      "算法迭代次数: 2\n"
     ]
    }
   ],
   "source": [
    "# Perceptron 学习规则\n",
    "# 作业： P40 习题2.5\n",
    "# 反复训练，直到网络输出误差为零\n",
    "X = np.array([[2,1,-1],[0,-1,-1]])\n",
    "y = np.array([-1,1])\n",
    "lr = 1    # 学习率\n",
    "rule =  'perceptron' # 学习规则\n",
    "act = 'sgn' #  # 激活函数\n",
    "epochs = 100    # 训练次数\n",
    "init_w = np.array([0,1,0])  # 初始化权向量  \n",
    "\n",
    "print(f'学习规则：{rule}')\n",
    "print('激活函数：{}'.format(ac.func_name[act]))\n",
    "print(f'学习率：{lr}')\n",
    "\n",
    "final_w = runner(X,y=y,rule=rule,act=act,lr=lr,epochs=epochs,init_w=init_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611fc95",
   "metadata": {},
   "source": [
    "&nbsp; $\\cdot $ &nbsp;$\\delta$ 学习规则的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b5f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "学习规则：delta\n",
      "激活函数：Sigmoid_d\n",
      "学习率：0.1\n",
      "初始权值向量:  [ 0.5  1.  -1.   0. ]\n",
      "\n",
      "Epoch: 0\n",
      "当前输入的训练数据:  [-1.  1. -2.  0.] -1\n",
      "净输入: net = w * x.T = 2.500\n",
      "实际输出: o = f(net) = 0.848\n",
      "导数：f'(net) = 0.140\n",
      "学习信号：r(w,x,d) = -0.259\n",
      "更新的权值向量:  [ 0.526  0.974 -0.948  0.   ]\n",
      "\n",
      "Epoch: 1\n",
      "当前输入的训练数据:  [-1.   0.   1.5 -0.5] -1\n",
      "净输入: net = w * x.T = -1.948\n",
      "实际输出: o = f(net) = -0.750\n",
      "导数：f'(net) = 0.218\n",
      "学习信号：r(w,x,d) = -0.054\n",
      "更新的权值向量:  [ 0.531  0.974 -0.956  0.003]\n",
      "\n",
      "Epoch: 2\n",
      "当前输入的训练数据:  [-1.  -1.   1.   0.5] 1\n",
      "净输入: net = w * x.T = -2.460\n",
      "实际输出: o = f(net) = -0.843\n",
      "导数：f'(net) = 0.145\n",
      "学习信号：r(w,x,d) = 0.267\n",
      "更新的权值向量:  [ 0.505  0.947 -0.93   0.016]\n"
     ]
    }
   ],
   "source": [
    "# Delta 学习规则\n",
    "# P37 例2.2  Delta学习规则\n",
    "# 样本\n",
    "X = np.array([[-1,1,-2,0],[-1,0,1.5,-0.5],[-1,-1,1,0.5]])\n",
    "# 期望输出 d = y\n",
    "y = np.array([-1,-1,1]) \n",
    "lr = 0.1    # 学习率\n",
    "rule =  'delta' # 学习规则\n",
    "act = 'sigmoid_d' #    激活函数\n",
    "epochs = 3    # 训练次数\n",
    "init_w = np.array([0.5,1,-1,0]) # 初始化权向量  \n",
    "\n",
    "print(f'\\n学习规则：{rule}')\n",
    "print('激活函数：{}'.format(ac.func_name[act]))\n",
    "print(f'学习率：{lr}')\n",
    "\n",
    "final_w = runner(X,y=y,rule=rule,act=act,lr=lr,epochs=epochs,init_w=init_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10286dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "学习规则：delta\n",
      "激活函数：Sigmoid_d\n",
      "学习率：0.25\n",
      "初始权值向量:  [1 0 1]\n",
      "\n",
      "Epoch: 0\n",
      "当前输入的训练数据:  [ 2  0 -1] -1\n",
      "净输入: net = w * x.T = 1.000\n",
      "实际输出: o = f(net) = 0.462\n",
      "导数：f'(net) = 0.393\n",
      "学习信号：r(w,x,d) = -0.575\n",
      "更新的权值向量:  [0.713 0.    1.144]\n",
      "\n",
      "Epoch: 1\n",
      "当前输入的训练数据:  [ 1 -2 -1] 1\n",
      "净输入: net = w * x.T = -0.431\n",
      "实际输出: o = f(net) = -0.212\n",
      "导数：f'(net) = 0.477\n",
      "学习信号：r(w,x,d) = 0.579\n",
      "更新的权值向量:  [ 0.857 -0.289  0.999]\n",
      "\n",
      "Epoch: 2\n",
      "当前输入的训练数据:  [ 2  0 -1] -1\n",
      "净输入: net = w * x.T = 0.715\n",
      "实际输出: o = f(net) = 0.343\n",
      "导数：f'(net) = 0.441\n",
      "学习信号：r(w,x,d) = -0.592\n",
      "更新的权值向量:  [ 0.561 -0.289  1.147]\n"
     ]
    }
   ],
   "source": [
    "# Delta 学习规则\n",
    "# 作业： P41 习题2.6\n",
    "# 样本\n",
    "X = np.array([[2,0,-1],[1,-2,-1]])\n",
    "# 期望输出 d = y\n",
    "y = np.array([-1,1]) \n",
    "lr = 0.25    # 学习率\n",
    "rule =  'delta' # 学习规则\n",
    "act = 'sigmoid_d' #    激活函数\n",
    "epochs = 3    # 训练次数\n",
    "init_w = np.array([1,0,1]) # 初始化权向量  \n",
    "\n",
    "print(f'\\n学习规则：{rule}')\n",
    "print('激活函数：{}'.format(ac.func_name[act]))\n",
    "print(f'学习率：{lr}')\n",
    "\n",
    "final_w = runner(X,y=y,rule=rule,act=act,lr=lr,epochs=epochs,init_w=init_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075a5c0",
   "metadata": {},
   "source": [
    "&nbsp; $\\cdot $ &nbsp;Widrow-Hoff (最小均方LMS) 学习规则的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02e39bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "学习规则：LMS\n",
      "激活函数：None\n",
      "学习率：0.25\n",
      "初始权值向量:  [1 0 1]\n",
      "\n",
      "Epoch: 0\n",
      "当前输入的训练数据:  [ 2  0 -1] -1\n",
      "净输入: net = w * x.T = 1.000\n",
      "实际输出: o = net = 1.000\n",
      "学习信号：r(w,x,d) = -2.000\n",
      "更新的权值向量:  [0.  0.  1.5]\n",
      "\n",
      "Epoch: 1\n",
      "当前输入的训练数据:  [ 1 -2 -1] 1\n",
      "净输入: net = w * x.T = -1.500\n",
      "实际输出: o = net = -1.500\n",
      "学习信号：r(w,x,d) = 2.500\n",
      "更新的权值向量:  [ 0.625 -1.25   0.875]\n",
      "\n",
      "Epoch: 2\n",
      "当前输入的训练数据:  [ 2  0 -1] -1\n",
      "净输入: net = w * x.T = 0.375\n",
      "实际输出: o = net = 0.375\n",
      "学习信号：r(w,x,d) = -1.375\n",
      "更新的权值向量:  [-0.062 -1.25   1.219]\n"
     ]
    }
   ],
   "source": [
    "# Widrow-Hoff 学习规则\n",
    "# 作业： P41 习题2.7\n",
    "# 样本\n",
    "X = np.array([[2,0,-1],[1,-2,-1]])\n",
    "# 期望输出 d = y\n",
    "y = np.array([-1,1]) \n",
    "lr = 0.25    # 学习率\n",
    "rule =  'LMS' # 学习规则\n",
    "act = None #    激活函数\n",
    "epochs = 3    # 训练次数\n",
    "init_w = np.array([1,0,1]) # 初始化权向量  \n",
    "\n",
    "print(f'\\n学习规则：{rule}')\n",
    "print('激活函数：None')\n",
    "print(f'学习率：{lr}')\n",
    "\n",
    "final_w = runner(X,y=y,rule=rule,act=act,lr=lr,epochs=epochs,init_w=init_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34131014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeakyReLU\n",
      "<nn_tool.activation.LeakyReLU object at 0x000001313059A750>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m afunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mac.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mac\u001b[38;5;241m.\u001b[39mfunc_name[func]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(afunc)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(afunc\u001b[38;5;241m.\u001b[39mformula())\n",
      "File \u001b[1;32mD:\\Documents\\WPS云盘\\WPS云盘\\WJ\\教学工作\\mycourse\\nn\\code\\chap2\\nn_tool\\activation.py:245\u001b[0m, in \u001b[0;36mLeakyReLU.formula\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformula\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m()\n",
      "File \u001b[1;32mD:\\Documents\\WPS云盘\\WPS云盘\\WJ\\教学工作\\mycourse\\nn\\code\\chap2\\nn_tool\\activation.py:242\u001b[0m, in \u001b[0;36mLeakyReLU.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):        \n\u001b[0;32m    241\u001b[0m     z \u001b[38;5;241m=\u001b[39m symbols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sympy\u001b[38;5;241m.\u001b[39mPiecewise((a\u001b[38;5;241m*\u001b[39mz,z\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0\u001b[39m),(z,z\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a = 0.5\n",
    "func = 'leakyRelu'\n",
    "print(ac.func_name[func])\n",
    "#afunc = eval(f'ac.{ac.func_name[fname]}({a})')\n",
    "afunc = eval(f'ac.{ac.func_name[func]}({a})')\n",
    "print(afunc)\n",
    "print(afunc.formula())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9443608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153daad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
